{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy4/N569vU/BdmAjt/yvVz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamck/CudaColab/blob/main/CUDA_Chapter_2_Image_Dilation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to Cuda C++ Tutorials in Google Colab\n",
        "This tutorial series will start from scratch and will assume no knowledge about CUDA.\n",
        "\n",
        "## Chapter 2 : Dilate an Image on the GPU using CUDA C++ and OpenCV\n",
        "\n",
        "### Setting up Colab with Nvidia GPU\n",
        "Follow [Chapter 1](https://github.com/shubhamck/CoronaCV/blob/master/CUDA_Chapter_1_Scale.ipynb) for setting up GPU for the notebook\n",
        "\n",
        "So Now Lets test if Google gave us our GPU. Run `nvidia-smi`"
      ],
      "metadata": {
        "id": "gr66uKopSNMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!which nvcc\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Irv9BhK_DqN",
        "outputId": "07917df9-4943-4c5e-b53e-56b8b679e325"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda/bin/nvcc\n",
            "Sun Aug 11 04:08:41 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> # â›” Alert\n",
        "> Google only allows free GPU access for a limited time.\n",
        "> I suggest `Change Runtime` back to `CPU` while coding or if you keep the `GPU` ON for a long time Google will ask you to pay to cotinue using it"
      ],
      "metadata": {
        "id": "Q5s11tSEXFo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing a simple cuda kernel to dilate an image using a user-defined dilation template\n",
        "\n",
        "Lets look at the steps to do this:\n",
        "\n",
        "1. Read the input image using `opencv` and store it on the CPU\n",
        "2. Create a pointer called `device input pointer` which will point to the memory location on the GPU where the input image will be copied\n",
        "3. Create a point called `device output pointer` which will point to the memory location on the GPU where the resulting image will be filled\n",
        "4. Copy the input array to the GPU\n",
        "5. Run the Kernel\n",
        "6. Copy the the result image back to the CPU\n",
        "7. Verify if the image got dilated"
      ],
      "metadata": {
        "id": "FJlI81AoZCGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenCV C++\n",
        "\n",
        "OpenCV is preinstalled in ALL Google Colab notebooks. Lets try to use it in a simple program first and read an image and print its size"
      ],
      "metadata": {
        "id": "QTZOwbU36eSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile opencv_test.cpp\n",
        "\n",
        "#include<stdio.h>\n",
        "#include <iostream>\n",
        "#include \"../include/opencv4/opencv2/opencv_modules.hpp\"\n",
        "#include \"../include/opencv4/opencv2/opencv.hpp\"\n",
        "#include \"../include/opencv4/opencv2/core/core.hpp\"\n",
        "#include \"../include/opencv4/opencv2/highgui/highgui.hpp\"\n",
        "#include \"../include/opencv4/opencv2/imgproc/imgproc.hpp\"\n",
        "\n",
        "int main()\n",
        "{\n",
        "  cv::Mat img = cv::imread(\"chess.png\", CV_8UC1);\n",
        "  std::cout << \"Image size : \" << img.size();\n",
        "  std::cout << \"rows : \" << img.rows << \", cols : \" << img.cols << \"\\n\";\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrXqKthZ6rpB",
        "outputId": "e7b5eee1-88f0-4882-9cf9-4f183c0421a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing opencv_test.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Lets build the code."
      ],
      "metadata": {
        "id": "QHNmwEz8B2bB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ opencv_test.cpp -o opencv_test -I/usr/include/opencv4 -lopencv_imgcodecs -lopencv_imgproc -lopencv_core"
      ],
      "metadata": {
        "id": "MTJYN4MI9P2-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And Run it"
      ],
      "metadata": {
        "id": "RtFbYInKCuNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./opencv_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuJgDiUS9dpT",
        "outputId": "1d206485-c9d5-479d-b052-ae7099e93013"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size : [800 x 800]rows : 800, cols : 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used `chess.png` which looks something like this\n",
        "\n",
        "![chess.png](https://i.postimg.cc/ncyyDkR5/chess.png)\n"
      ],
      "metadata": {
        "id": "I-hviBfZout0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Dilation in Parallel\n",
        "\n",
        "Lets look at the dilation from Parallelization Point of View\n",
        "\n",
        "1. The Dilation Template or Kernel operates on each pixel of the input image\n",
        "2. When the template is on a pixel, it finds the `max` of all the pixels falling under the template\n",
        "3. This max value is then assigned to the corresponding pixel in the output image\n",
        "\n",
        "![Dilation_img](https://i.postimg.cc/MTpWCmh9/dilation-shift.gif)\n",
        "Image Source : https://python.plainenglish.io/image-dilation-explained-easily-e085c47fbac2\n",
        "\n",
        "So parallelizing this operation is quite easy\n",
        "\n",
        "1. Spawn a thread for each pixel in the input image\n",
        "2. Each thread gets its pixel location `loc` from thread identifier\n",
        "3. For the pixel the template max is calculated\n",
        "4. This value is then written to the output image pixel location `loc`\n",
        "\n",
        "How to spawn threads ?\n",
        "\n",
        "1. We need total of `num_pixels = num_rows * num_cols` number of threads\n",
        "2. If we just call the kernel same as Chapter 1 with `1 block` and `num_pixels threads` we might end up exhausting the number of available threads per block which would result in slowing down of the kernel as the GPU can only spawn a fixed number of threads at a time\n",
        "3. To tackle this we can make use of multiple `blocks`\n",
        "4. We can call `num_rows` number of `blocks` with each block containing `num_cols` number of `threads`\n",
        "5. The syntax for that is `dilation <<< num_rows, num_cols >>>`"
      ],
      "metadata": {
        "id": "T_7soqwMCzDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dilate.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include <iostream>\n",
        "#include \"../include/opencv4/opencv2/opencv_modules.hpp\"\n",
        "#include \"../include/opencv4/opencv2/opencv.hpp\"\n",
        "#include \"../include/opencv4/opencv2/core/core.hpp\"\n",
        "#include \"../include/opencv4/opencv2/highgui/highgui.hpp\"\n",
        "#include \"../include/opencv4/opencv2/imgproc/imgproc.hpp\"\n",
        "\n",
        "// helper function to get row major index\n",
        "__device__ int row_major_location(int row_id, int col_id, int num_cols)\n",
        "{\n",
        "  return row_id * num_cols + col_id;\n",
        "}\n",
        "\n",
        "// Kernel which runs on every thread\n",
        "__global__ void dilate(uchar* in_buffer, uchar* out_buffer, int dilation_kernel_size, int num_rows, int num_cols)\n",
        "{\n",
        "    // Each thread knows its block ID and block id is the row id\n",
        "    int row_id = blockIdx.x;\n",
        "    // Each thread knows its ID and thread id is the col id\n",
        "    int col_id = threadIdx.x;\n",
        "\n",
        "    // Get pixel location ( assuming in_buffer is row major flattened image )\n",
        "    int pixel_location = row_major_location(row_id, col_id, num_cols);\n",
        "\n",
        "    uchar max_value = 0U; // initialize the max value to zero;\n",
        "\n",
        "    for (int i = row_id - dilation_kernel_size; i < row_id + dilation_kernel_size; ++i)\n",
        "    {\n",
        "      for (int j = col_id - dilation_kernel_size; j < col_id + dilation_kernel_size; ++j)\n",
        "      {\n",
        "\n",
        "        // check if location is valid i.e inside the image dimensions\n",
        "        if (i >= 0 && j >= 0 && i < num_rows && j < num_cols)\n",
        "        {\n",
        "          uchar pixel_val = in_buffer[row_major_location(i, j, num_cols)];\n",
        "          if (pixel_val > max_value)\n",
        "          {\n",
        "            max_value = pixel_val;\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "    // write the max value to the output buffer for the same pixel location\n",
        "    out_buffer[pixel_location] = max_value;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc,char **argv)\n",
        "{\n",
        "    constexpr int SQUARE_KERNEL_SIZE = 10; // 10x10 square Kernel\n",
        "\n",
        "    auto input_img = cv::imread(\"chess.png\", CV_8UC1);\n",
        "    std::cout << \"Size : \" << input_img.size() << \"\\n\";\n",
        "    std::cout << \"rows : \" << input_img.rows << \", cols : \" << input_img.cols << \"\\n\";\n",
        "\n",
        "    const auto num_rows = input_img.rows;\n",
        "    const auto num_cols = input_img.cols;\n",
        "    const auto num_pixels = num_rows * num_cols;\n",
        "    const auto img_size_bytes = num_pixels * sizeof(uchar);\n",
        "\n",
        "    // Declare output image on CPU\n",
        "    cv::Mat output_img(num_rows, num_cols, CV_8UC1);\n",
        "\n",
        "    // Declare pointer on CPU which pdvsdvdssdfoint to memory locations on GPU global memory\n",
        "    uchar* d_input_buffer;\n",
        "    uchar* d_output_buffer;\n",
        "\n",
        "    // Allocate memory on the GPU\n",
        "    cudaMalloc((void**) &d_input_buffer, img_size_bytes);\n",
        "    cudaMalloc((void**) &d_output_buffer, img_size_bytes);\n",
        "\n",
        "    // Copy input array from CPU to GPU\n",
        "    cudaMemcpy(d_input_buffer, input_img.data, img_size_bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Run the Kernel\n",
        "    dilate<<<num_rows, num_cols>>>(d_input_buffer, d_output_buffer, SQUARE_KERNEL_SIZE, num_rows, num_cols);\n",
        "\n",
        "    // Copy output array from GPU to CPU\n",
        "    cudaMemcpy(output_img.data, d_output_buffer, img_size_bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Free the memory on the GPU\n",
        "    cudaFree(d_input_buffer);\n",
        "    cudaFree(d_output_buffer);\n",
        "\n",
        "    // Flush\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "\n",
        "    // write the output image\n",
        "    cv::imwrite(\"chess_dilate_gpu.png\", output_img);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsPNLrNp_MYS",
        "outputId": "3f870e1c-7c44-425f-82dd-487fccf6590f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dilate.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets compile the code."
      ],
      "metadata": {
        "id": "PMPdZi6Pi37S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /usr/local/cuda\n",
        "!ln -s /usr/local/cuda-12.2 /usr/local/cuda\n",
        "!nvcc -g -G dilate.cu -o dilate -I/usr/include/opencv4 -lopencv_imgcodecs -lopencv_imgproc -lopencv_core"
      ],
      "metadata": {
        "id": "Dz4pCdMh_T2c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will generate `dilate` binary in the current directly. You can run this binary and see the output"
      ],
      "metadata": {
        "id": "Ljc4sPrXjCCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./dilate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzkXoHKF_kgC",
        "outputId": "52f8082b-9a73-493c-a941-75e4dc1c1a8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size : [800 x 800]\n",
            "rows : 800, cols : 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the code runs successfully for the `10x10` dilation kernel you should get the following image\n",
        "![chess_dilate_gpu.png](https://i.postimg.cc/MK1nRsZf/chess-dilate-gpu.png)\n"
      ],
      "metadata": {
        "id": "xFqDCeEJpDZI"
      }
    }
  ]
}